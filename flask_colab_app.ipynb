{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flask_colab_app.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Fqf4pATEh4QxmIPVZD_XD-vrWgYnfso",
      "authorship_tag": "ABX9TyNaiHLYaNcuBckZbtpLiqwA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andBabaev/awesome-action-recognition/blob/master/flask_colab_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDSF206GJbPD",
        "colab_type": "code",
        "outputId": "9bbcfd4f-0bc1-47b3-fa2b-ea2bad35794a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25GKZBoSNGZT",
        "colab_type": "code",
        "outputId": "27947582-246a-4356-9d80-cf7db3abe355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install pafy\n",
        "!pip install youtube_dl --upgrade"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pafy\n",
            "  Downloading https://files.pythonhosted.org/packages/74/69/829919eeadff695338f98fa12bb99e45490761a2010c8d688d88b6df194a/pafy-0.5.5-py2.py3-none-any.whl\n",
            "Installing collected packages: pafy\n",
            "Successfully installed pafy-0.5.5\n",
            "Collecting youtube_dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/5b/45dc2845a6203949cc70b16398e78c376178e90c757a5778caf0789ebd50/youtube_dl-2020.6.6-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2020.6.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfhqM4mdL7nO",
        "colab_type": "code",
        "outputId": "49f437dc-c86b-4f99-9629-9cf2838c542b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, render_template, Response, request, url_for\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, TimeDistributed, LSTM, Input, Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import  Multiply, Lambda, Flatten, Concatenate, Permute, Conv2D,Reshape, BatchNormalization\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pafy\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import seaborn as sns\n",
        "import os\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlv-TJZZMDu9",
        "colab_type": "code",
        "outputId": "739e981a-52b8-4fc1-c396-2fc4309bc7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "target_classes = ['bicycling', 'cooking', 'dancing', 'drawing', 'drinking',\n",
        "                  'eating', 'crying', 'walking', 'exercising', 'jumping']\n",
        "n_channels = 3\n",
        "len_seq = 10 \n",
        "fps = 5\n",
        "image_shape = (224,224)\n",
        "\n",
        "#model = load_model('/content/drive/My Drive/roonyx_models/Mobnet_overfitting')\n",
        "\n",
        "inputs = Input((len_seq, *image_shape,n_channels))\n",
        "base_model = MobileNetV2(weights='imagenet',include_top=False, input_shape=(*image_shape,n_channels))\n",
        "outputs = TimeDistributed(base_model)(inputs)\n",
        "x = TimeDistributed(GlobalAveragePooling2D())(outputs)\n",
        "x = LSTM(128, dropout=0.5, return_sequences=True)(x)\n",
        "x = LSTM(128)(x)\n",
        "preds = Dense(len(target_classes), activation='softmax')(x)\n",
        "model = Model(inputs,preds)\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/roonyx_models/mobnet_2lstm128_mit_full_final_weights/full_model_weights-06-0.61.h5')\n",
        "print('Model loading is completed')\n",
        "\n",
        "model.compile(optimizer=Adam(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Model loading is completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAI9uOlIrUQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heatmap_model = tf.keras.models.Model(\n",
        "    [model.inputs], [model.layers[1].output, model.output]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwEM8MMhJPb4",
        "colab_type": "text"
      },
      "source": [
        "waling bad https://www.youtube.com/watch?v=T4h1t7QQY64\n",
        "\n",
        "walking good https://www.youtube.com/watch?v=NyLF8nHIquM\n",
        "\n",
        "bicycling  https://www.youtube.com/watch?v=UdTu8v6cWVo\n",
        "\n",
        "cooking https://www.youtube.com/watch?v=6DOgPETTyoU\n",
        "\n",
        "drawing https://www.youtube.com/watch?v=GMQPiO7Xfw8\n",
        "\n",
        "drinking https://www.youtube.com/watch?v=Lw1xWh-z-nA\n",
        "\n",
        "crying https://www.youtube.com/watch?v=ee925OTFBCA\n",
        "\n",
        "training https://www.youtube.com/watch?v=5nZ8n1vUqVU https://www.youtube.com/watch?v=_K7rv_vFOWM\n",
        "\n",
        "dancing https://www.youtube.com/watch?v=uUGsLoZYXb4\n",
        "\n",
        "eating https://www.youtube.com/watch?v=eO8oUffeeIY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpFnU-32KcUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86b0cd92-6ec8-4d3c-f5ee-e6c7be006f50"
      },
      "source": [
        "!mkdir 'templates/'\n",
        "!mkdir 'static/'\n",
        "!mkdir 'static/css/'\n",
        "# t = '''\n",
        "# <html>\n",
        "#   <head>\n",
        "#     <title>Demo</title>\n",
        "#   </head>\n",
        "#   <body>\n",
        "#     <h1 align=center>Action Recognition Demonstration</h1>\n",
        "#     <div align=center>\n",
        "#         <img id=\"bg\" src=\"{{ video_output }}\">\n",
        "#     </div>\n",
        "#     <form align=center method=\"POST\">\n",
        "#         <input name=\"text\" value=\"https://www.youtube.com/watch?v=UdTu8v6cWVo\">\n",
        "#         <input type=\"submit\">\n",
        "#     </form>\n",
        "#   </body>\n",
        "# </html>'''\n",
        "# with open('templates/index.html', 'w') as f:\n",
        "#     f.write(t)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘templates/’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWyioN-GJhQ2",
        "colab_type": "code",
        "outputId": "35ced2b7-28aa-4996-d4ae-969acdebe757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "CAM_visible = False\n",
        "all_scores_visible = True\n",
        "\n",
        "def gen(url):\n",
        "    X = np.empty((0, *image_shape, n_channels))\n",
        "    current_action = 'No action'\n",
        "    #scale_coef = 0.5\n",
        "    alpha=0.5\n",
        "    colormap=cv2.COLORMAP_VIRIDIS\n",
        "\n",
        "    vPafy = pafy.new(url)\n",
        "    play = vPafy.getbest(preftype=\"mp4\")\n",
        "    video = cv2.VideoCapture(play.url)\n",
        "    \n",
        "    frame_step = int(video.get(cv2.CAP_PROP_FPS) / fps)+1\n",
        "    wait_time = 1/video.get(cv2.CAP_PROP_FPS)\n",
        "    temp_step = 0\n",
        "    print(wait_time)\n",
        "    success, frame = video.read()\n",
        "    heatmap = np.zeros_like(frame)\n",
        "    \n",
        "    \n",
        "    if frame.shape[0] < 400:\n",
        "        scale_coef = 400 / frame.shape[0] \n",
        "    elif frame.shape[0] > 720:\n",
        "        scale_coef = 720 / frame.shape[0]\n",
        "    else:\n",
        "        scale_coef = 1.0\n",
        "    print(frame.shape)\n",
        "\n",
        "    #black_area = np.full((frame.shape[0],300, 3), 0)\n",
        "    preds = None\n",
        "    while True:\n",
        "\n",
        "        success, frame = video.read()\n",
        "        if success:\n",
        "            if temp_step % frame_step == 0:\n",
        "                X = np.vstack((X, cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), \n",
        "                                        image_shape, \n",
        "                                        interpolation=cv2.INTER_AREA)[np.newaxis,...]))\n",
        "                temp_step = 0\n",
        "            temp_step += 1\n",
        "\n",
        "            if X.shape[0] == len_seq:\n",
        "\n",
        "                if not CAM_visible:\n",
        "                    preds = model.predict(X[np.newaxis,...]/255.0)\n",
        "                    heatmap = np.zeros_like(frame)\n",
        "                else:\n",
        "\n",
        "                    with tf.GradientTape() as tape:\n",
        "                        conv_output, preds = heatmap_model(X[np.newaxis,...]/255.)\n",
        "                        loss = preds[:, np.argmax(preds[0])]\n",
        "                    grads = tape.gradient(loss, conv_output)[:, -1]\n",
        "                    conv_output = conv_output[:, -1]\n",
        "                    \n",
        "                    castConvOutputs = tf.cast(conv_output > 0, \"float32\")\n",
        "                    castGrads = tf.cast(grads > 0, \"float32\")\n",
        "                    guidedGrads = castConvOutputs * castGrads * grads\n",
        "                    \n",
        "                    conv_output = conv_output[0]\n",
        "                    guidedGrads = guidedGrads[0]\n",
        "\n",
        "                    weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
        "                    cam = tf.reduce_sum(tf.multiply(weights, conv_output), axis=-1)\n",
        "\n",
        "                    (w, h) = (frame.shape[1], frame.shape[0])\n",
        "                    heatmap = cv2.resize(cam.numpy(), (w, h))\n",
        "\n",
        "                    eps=1e-8\n",
        "                    numer = heatmap - np.min(heatmap)\n",
        "                    denom = (heatmap.max() - heatmap.min()) + eps\n",
        "                    heatmap = numer / denom\n",
        "                    heatmap = (heatmap * 255).astype(\"uint8\")\n",
        "                    heatmap = cv2.applyColorMap(heatmap, colormap)\n",
        "                    \n",
        "\n",
        "                preds = preds[0]\n",
        "                if np.max(preds) >= 0.55:\n",
        "                    current_action = target_classes[np.argmax(preds)] + ' ' + str(np.round(np.max(preds), 2))\n",
        "                else:\n",
        "                    current_action = 'No action'\n",
        "                X = X[1:]\n",
        "            else:\n",
        "                time.sleep(wait_time)\n",
        "            \n",
        "            frame = cv2.addWeighted(frame.astype(\"uint8\"), alpha, heatmap, 1 - alpha, 0,)\n",
        "            #frame = np.hstack([black_area, frame])\n",
        "            frame = cv2.rectangle(frame, (0,0), (300,50), (0,0,0), -1)\n",
        "\n",
        "                        \n",
        "            \n",
        "            if frame.shape[0] > 1.0:\n",
        "                frame = cv2.resize(frame, None, fx=scale_coef, fy=scale_coef, \n",
        "                                   interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            frame = cv2.putText(frame, current_action, (25, 30), cv2.FONT_HERSHEY_SIMPLEX ,  \n",
        "                            1, (255, 255, 255) , 2, cv2.LINE_AA) \n",
        "            if preds is not None and all_scores_visible:\n",
        "                for i, (class_, score) in enumerate(zip(target_classes, preds), 1):\n",
        "                    text = class_ + ' ' + str(np.round(score, 2))\n",
        "                    frame = cv2.putText(frame, text, (25, 60+27*i), cv2.FONT_HERSHEY_SIMPLEX ,  \n",
        "                                0.8, (255, 255, 255) , 2, cv2.LINE_AA) \n",
        "\n",
        "            #frame = cv2.resize(frame, None, fx=scale_coef, fy=scale_coef, interpolation=cv2.INTER_AREA)\n",
        "            if frame.shape[0] < 1.0:\n",
        "                frame = cv2.resize(frame, None, fx=scale_coef, fy=scale_coef, \n",
        "                                   interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            ret, jpeg = cv2.imencode('.jpg', frame)\n",
        "            frame = jpeg.tobytes()\n",
        "        else:\n",
        "            video.release()\n",
        "            break\n",
        "\n",
        "        yield (b'--frame\\r\\n'\n",
        "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n\\r\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    # rendering webpage\n",
        "    return render_template('index.html', \n",
        "                           video_output='static/start_rec.jpg', \n",
        "                           box_cam=CAM_visible, \n",
        "                           box_scores=all_scores_visible,\n",
        "                           url_video='https://www.youtube.com/watch?v=UdTu8v6cWVo')\n",
        "\n",
        "@app.route('/video_feed/<path:url>')\n",
        "def video_feed(url):\n",
        "    #url = 'https://www.youtube.com/watch?v=UdTu8v6cWVo'\n",
        "    return Response(gen(url),\n",
        "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "  \n",
        "@app.route('/form_url', methods=['POST'])\n",
        "def form_url():\n",
        "    url_ = request.form['text']\n",
        "    if 'youtube' in url_:\n",
        "        new_src = url_for('video_feed', url=url_)\n",
        "        return render_template('index.html',\n",
        "                            video_output=new_src, \n",
        "                            box_cam=CAM_visible, \n",
        "                            box_scores=all_scores_visible,\n",
        "                            url_video=url_)\n",
        "    else:\n",
        "        return '', 204\n",
        "    \n",
        "@app.route('/form_cam', methods=['POST'])\n",
        "def form_cam():\n",
        "    global CAM_visible, all_scores_visible\n",
        "    CAM_visible = True if request.form.get('activator') is not None else False\n",
        "    all_scores_visible = True if request.form.get('all_scores') is not None else False\n",
        "    return '', 204\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://157fdb296e59.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [10/Jun/2020 15:55:58] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [10/Jun/2020 15:55:58] \"\u001b[37mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [10/Jun/2020 15:55:58] \"\u001b[37mGET /static/start_rec.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [10/Jun/2020 15:55:59] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [10/Jun/2020 15:56:01] \"\u001b[37mPOST /form_url HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [10/Jun/2020 15:56:02] \"\u001b[37mGET /video_feed/https://www.youtube.com/watch%3Fv%3DUdTu8v6cWVo HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.04170833333333333\n",
            "(720, 1280, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [10/Jun/2020 15:56:14] \"\u001b[37mPOST /form_url HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [10/Jun/2020 15:56:16] \"\u001b[37mGET /video_feed/https://www.youtube.com/watch%3Fv%3DLw1xWh-z-nA HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.03333333333333333\n",
            "(720, 406, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [10/Jun/2020 15:56:27] \"\u001b[37mPOST /form_cam HTTP/1.1\u001b[0m\" 204 -\n",
            "127.0.0.1 - - [10/Jun/2020 15:56:27] \"\u001b[37mPOST /form_cam HTTP/1.1\u001b[0m\" 204 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4na4mtMBltk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsM3Zkcwil1p",
        "colab_type": "text"
      },
      "source": [
        "# HMDB51"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt6YkivdBlnG",
        "colab_type": "code",
        "outputId": "af79305a-e2ba-4b21-999d-d78bf117b389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "target_classes = ['fall_floor', 'punch', 'smoke', 'sit', 'walk']\n",
        "n_channels = 3\n",
        "len_seq = 10 \n",
        "fps = 5\n",
        "image_shape = (224,224)\n",
        "seqShape = (len_seq, *image_shape,n_channels)\n",
        "inputs = Input(seqShape)\n",
        "base_model = MobileNetV2(weights='imagenet',include_top=False, input_shape=(*image_shape,n_channels))\n",
        "outputs = TimeDistributed(base_model)(inputs)\n",
        "x = Permute((2, 3, 4, 1))(outputs)\n",
        "x = Reshape((7,7,1280*len_seq))(x)\n",
        "x = Conv2D(1280, (1,1), padding='same', activation='relu')(x)\n",
        "\n",
        "inputs_1 = Input((*image_shape,n_channels))\n",
        "base_model_1 = MobileNetV2(weights='imagenet',include_top=False, input_shape=(*image_shape,n_channels))\n",
        "outputs_1 = base_model_1(inputs_1)\n",
        "\n",
        "x = Concatenate(axis=3)([x, outputs_1])\n",
        "x = Conv2D(1024, (1,1), padding='same', activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(1024, (3,3), padding='same', activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "def f(x):\n",
        "    F_T = Reshape((49, 1024))(x)\n",
        "    F = tf.transpose(F_T, perm=(0,2,1))\n",
        "    F_T = tf.linalg.matmul(F, F_T)\n",
        "    M = tf.nn.softmax(F_T)\n",
        "    F_ = tf.linalg.matmul(M, F)\n",
        "    F_ = tf.transpose(F_, perm=(0,2,1))\n",
        "    F__ = Reshape((7,7,1024))(F_)\n",
        "    return x+F__\n",
        "\n",
        "x = Lambda(f)(x)\n",
        "x = Conv2D(1024, (3,3), padding='same', activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(1024, (1,1), padding='same', activation='relu')(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(512)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "preds = Dense(len(target_classes), activation='softmax')(x)\n",
        "\n",
        "model = Model([inputs, inputs_1], preds)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           [(None, 10, 224, 224 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 10, 7, 7, 128 2257984     input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 7, 7, 1280, 1 0           time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 7, 7, 12800)  0           permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_21 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 7, 7, 1280)   16385280    reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Model)    (None, 7, 7, 1280)   2257984     input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           conv2d_5[0][0]                   \n",
            "                                                                 mobilenetv2_1.00_224[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 1024)   2622464     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 1024)   9438208     batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 7, 7, 1024)   4096        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 7, 7, 1024)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 1024)   9438208     lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 7, 7, 1024)   4096        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 1024)   1049600     batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 1024)         0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 5)            2565        dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 43,989,381\n",
            "Trainable params: 43,915,013\n",
            "Non-trainable params: 74,368\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2saDKj1i0jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model.layers[:135]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[135:]:\n",
        "    layer.trainable = True\n",
        "for layer in base_model_1.layers[:135]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model_1.layers[135:]:\n",
        "    layer.trainable = True\n",
        "model.load_weights('/content/drive/My Drive/roonyx_models/Mobnet_yowo_hmdb/Mobnet_yowo__hmdb51_final-43-0.64.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZrmtCjrlr0u",
        "colab_type": "code",
        "outputId": "2c9122f2-d7e0-46c5-847a-3cfe997576e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "def gen(url):\n",
        "    X = np.empty((0, *image_shape, n_channels))\n",
        "    current_action = 'No action'\n",
        "    scale_coef = 0.5\n",
        "    alpha=0.5\n",
        "    colormap=cv2.COLORMAP_VIRIDIS\n",
        "\n",
        "    vPafy = pafy.new(url)\n",
        "    play = vPafy.getbest(preftype=\"mp4\")\n",
        "    video = cv2.VideoCapture(play.url)\n",
        "    \n",
        "    frame_step = int(video.get(cv2.CAP_PROP_FPS) / fps)+1\n",
        "    wait_time = 1/video.get(cv2.CAP_PROP_FPS)\n",
        "    temp_step = 0\n",
        "\n",
        "    success, frame = video.read()\n",
        "    heatmap = np.zeros_like(frame)\n",
        "    while True:\n",
        "\n",
        "        success, frame = video.read()\n",
        "        if success:\n",
        "            if temp_step % frame_step == 0:\n",
        "                X = np.vstack((X, cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), \n",
        "                                        image_shape, \n",
        "                                        interpolation=cv2.INTER_AREA)[np.newaxis,...]))\n",
        "                temp_step = 0\n",
        "            temp_step += 1\n",
        "\n",
        "            if X.shape[0] == len_seq:\n",
        "                X_temp = preprocess_input(X)[np.newaxis,...]\n",
        "                preds = model.predict([X_temp, X_temp[:,-1]])\n",
        "                               \n",
        "\n",
        "                preds = preds[0]\n",
        "                if np.max(preds) >= 0.55:\n",
        "                    current_action = target_classes[np.argmax(preds)] + str(np.round(np.max(preds), 2))\n",
        "                else:\n",
        "                    current_action = 'No action'\n",
        "                X = X[1:]\n",
        "            else:\n",
        "                time.sleep(wait_time)\n",
        "            \n",
        "            frame = cv2.addWeighted(frame.astype(\"uint8\"), alpha, heatmap, 1 - alpha, 0,)\n",
        "            frame = cv2.rectangle(frame, (0,0), (300,50), (0,0,0), -1)\n",
        "            frame = cv2.putText(frame, current_action, (25, 30), cv2.FONT_HERSHEY_SIMPLEX ,  \n",
        "                            1, (255, 255, 255) , 2, cv2.LINE_AA) \n",
        "            frame = cv2.resize(frame, None, fx=scale_coef, fy=scale_coef, interpolation=cv2.INTER_AREA)\n",
        "            \n",
        "            ret, jpeg = cv2.imencode('.jpg', frame)\n",
        "            frame = jpeg.tobytes()\n",
        "        else:\n",
        "            video.release()\n",
        "            break\n",
        "\n",
        "        yield (b'--frame\\r\\n'\n",
        "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n\\r\\n')\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    # rendering webpage\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    url = 'https://www.youtube.com/watch?v=UdTu8v6cWVo'\n",
        "    return Response(gen(url),\n",
        "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "  \n",
        "app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://87dc236832a5.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [08/Jun/2020 16:02:56] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [08/Jun/2020 16:02:57] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [08/Jun/2020 16:02:59] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8SWWFc3PwlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}